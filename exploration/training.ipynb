{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you deployed mlflow\n",
    "%env MLFLOW_TRACKING_URI=http://localhost:5000\n",
    "%env MLFLOW_S3_ENDPOINT_URL=http://localhost:9000\n",
    "%env AWS_ACCESS_KEY_ID=minio\n",
    "%env AWS_SECRET_ACCESS_KEY=minio123\n",
    "\n",
    "# System libraries\n",
    "import sys\n",
    "import time\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "# Import DS librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import mlflow\n",
    "\n",
    "# Tensorflow Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/thomas/workspace/ml_project_example/\")\n",
    "from src.domain.model import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_for_training(data_path, batch_size):\n",
    "\n",
    "    image_dir = Path(data_path)\n",
    "    # Get filepaths and labels\n",
    "    filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.PNG'))\n",
    "    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "    # Concatenate filepaths and labels\n",
    "    image_df = pd.concat([filepaths, labels], axis=1)\n",
    "\n",
    "    # Separate in train and test data\n",
    "    train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "    # Train data generator\n",
    "    train_generator = ImageDataGenerator(validation_split=0.2)\n",
    "    # Test data generator\n",
    "    test_generator = ImageDataGenerator()\n",
    "\n",
    "    # Split the data into three categories.\n",
    "    train_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    val_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    test_images = test_generator.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_images, val_images, test_images, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to data\n",
    "data_path = \"../data\"\n",
    "\n",
    "# You should ensure you have a local mlflow server running\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"sea_animals_classification\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Exploration\"):\n",
    "\n",
    "    # hyperparams\n",
    "    denses = [256,256,19]\n",
    "    dropout = [0.2, 0.2]\n",
    "    adam_param = 0.00001\n",
    "    nb_epochs = 20\n",
    "    batch_size = 8\n",
    "    input_shape = (224, 224, 3)\n",
    "\n",
    "    # Logging hyper parameters to mlflow\n",
    "    mlflow.log_param(\"adam\", adam_param)\n",
    "    mlflow.log_param(\"dropout\", dropout)\n",
    "    mlflow.log_param(\"nb_dense\", denses)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"nb_epochs\", nb_epochs)\n",
    "    mlflow.log_param(\"input_shape\", input_shape)\n",
    "    print(\"Training parameters logged to tracking server.\")\n",
    "    \n",
    "    # Data Generators\n",
    "    train_images, val_images, test_images, test_df = generate_data_for_training(data_path, batch_size)\n",
    "    \n",
    "    # Model definition\n",
    "    model = build_model(input_shape, denses)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(adam_param),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    start_training_time = time.time()\n",
    "    history = model.fit(\n",
    "        train_images,\n",
    "        steps_per_epoch=len(train_images),\n",
    "        validation_data=val_images,\n",
    "        validation_steps=len(val_images),\n",
    "        epochs=nb_epochs\n",
    "    )\n",
    "    elapsed_training_time = time.time() - start_training_time\n",
    "\n",
    "    # Evaluate model\n",
    "    results = model.evaluate(test_images, verbose=1)\n",
    "\n",
    "    mlflow.log_metric(\"Training time\", elapsed_training_time)\n",
    "    mlflow.log_metric(\"Training accuracy\", history.history['accuracy'][0]*100)\n",
    "    mlflow.log_metric(\"Validation accuracy\", history.history['accuracy'][1]*100)\n",
    "    mlflow.log_metric(\"Test accuracy\", results[1]*100)\n",
    "    print(\"Metrics logged to tracking server.\")\n",
    "\n",
    "    tf.keras.models.save_model(model, \"./model\")\n",
    "    print(\"Model saved locally\")\n",
    "\n",
    "    # Log training script for audit purposes\n",
    "    try:\n",
    "        mlflow.log_artifacts(\"./training.ipynb\")\n",
    "        mlflow.log_artifacts(\"../src/domain/model.py\")\n",
    "        print(\"Training & model scripts logged as artifacts.\")\n",
    "    except Exception as e:\n",
    "        print(\"Impossible to log artifacts: {}\".format(e))\n",
    "\n",
    "    # Log model for reuse & comparison\n",
    "    try:\n",
    "        tag=[tf.compat.v1.saved_model.tag_constants.SERVING]\n",
    "        key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "        mlflow.tensorflow.log_model(tf_saved_model_dir=\"./model\",\n",
    "                                tf_meta_graph_tags=tag,\n",
    "                                tf_signature_def_key=key,\n",
    "                                artifact_path=\"model\",\n",
    "                                registered_model_name=\"MobileNetV2\")\n",
    "        print(\"Model sent to registry.\")\n",
    "    except Exception as e:\n",
    "        print(\"Impossible to log model to registry: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import make_confusion_matrix, plot_loss_curves\n",
    "\n",
    "# Plot loss curves\n",
    "plot_loss_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n",
    "\n",
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output confusion matrix\n",
    "make_confusion_matrix(y_test, pred, list(labels.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 25 random pictures from the dataset with their labels\n",
    "random_index = np.random.randint(0, len(test_df) - 1, 15)\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(test_df.Filepath.iloc[random_index[i]]))\n",
    "    if test_df.Label.iloc[random_index[i]] == pred[random_index[i]]:\n",
    "      color = \"green\"\n",
    "    else:\n",
    "      color = \"red\"\n",
    "    ax.set_title(f\"True: {test_df.Label.iloc[random_index[i]]}\\nPredicted: {pred[random_index[i]]}\", color=color)\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb5fc56c514ad5b078d293d6298dbbf8ff4fba0b34a78ce8c3bd71a8b6f43031"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
