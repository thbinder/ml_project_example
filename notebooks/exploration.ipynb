{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libraries\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Import DS librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "\n",
    "# Tensorflow Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "\n",
    "# Import Vision librairies\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "from PIL import UnidentifiedImageError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Origin : https://www.kaggle.com/datasets/vencerlanz09/sea-animals-image-dataste\n",
    "dataset = \"../../data/sea_animals\"\n",
    "image_dir = Path(dataset)\n",
    "\n",
    "# Get filepaths and labels\n",
    "filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.PNG'))\n",
    "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "# Concatenate filepaths and labels\n",
    "image_df = pd.concat([filepaths, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(dataset).rglob(\"*.jpg\")\n",
    "for img_p in path:\n",
    "    try:\n",
    "        img = PIL.Image.open(img_p)\n",
    "    except PIL.UnidentifiedImageError:\n",
    "            print(img_p)\n",
    "\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 16 picture of the dataset with their labels\n",
    "random_index = np.random.randint(0, len(image_df), 16)\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(image_df.Filepath[random_index[i]]))\n",
    "    ax.set_title(image_df.Label[random_index[i]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(image_df, batch_size):\n",
    "\n",
    "    # Separate in train and test data\n",
    "    train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "    train_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "\n",
    "    test_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input\n",
    "    )\n",
    "\n",
    "    # Split the data into three categories.\n",
    "    train_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    val_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    test_images = test_generator.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_images, val_images, test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize Layer\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Resizing(224,224),\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "])\n",
    "\n",
    "# Load the pretained model\n",
    "pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint callback\n",
    "checkpoint_path = \"sea_animal_classification_model_checkpoint\"\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_path,\n",
    "                                      save_weights_only=True,\n",
    "                                      monitor=\"val_accuracy\",\n",
    "                                      save_best_only=True)\n",
    "\n",
    "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
    "early_stopping = EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
    "                               patience = 5,\n",
    "                               restore_best_weights = True) # if val loss decreases for 3 epochs in a row, stop training\n",
    "\n",
    "# You should ensure you have a local mlflow server running\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"sea_animals_classification\")\n",
    "with mlflow.start_run(run_name=\"Experiment 1\"):\n",
    "\n",
    "    ### hyperparams\n",
    "    denses = [256,256,19]\n",
    "    dropout = [0.2, 0.2]\n",
    "    adam_param = 0.00001\n",
    "    batch_size = 4\n",
    "    \n",
    "    ### Data Generators\n",
    "    train_images, val_images, test_images = split(image_df, 4)\n",
    "    \n",
    "    ### Model\n",
    "    inputs = pretrained_model.input\n",
    "    x = resize_and_rescale(inputs)\n",
    "    x = Dense(denses[0], activation='relu')(pretrained_model.output)\n",
    "    x = Dropout(dropout[0])(x)\n",
    "    x = Dense(denses[1], activation='relu')(x)\n",
    "    x = Dropout(dropout[1])(x)\n",
    "    outputs = Dense(denses[2], activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    ### Mlflow logging params\n",
    "    mlflow.log_param(\"adam\", adam_param)\n",
    "    mlflow.log_param(\"dropout\", dropout)\n",
    "    mlflow.log_param(\"nb_dense\", denses)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    print(\"Training parameters logged to tracking server.\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(adam_param),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_images,\n",
    "        steps_per_epoch=len(train_images),\n",
    "        validation_data=val_images,\n",
    "        validation_steps=len(val_images),\n",
    "        epochs=2,\n",
    "        callbacks=[\n",
    "            early_stopping,\n",
    "            checkpoint_callback,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ### Evaluate model\n",
    "    results = model.evaluate(test_images, verbose=1)\n",
    "\n",
    "    mlflow.log_metric(\"train_loss\", history.history['loss'][0])\n",
    "    mlflow.log_metric(\"train_accuracy\", history.history['accuracy'][0]*100)\n",
    "    mlflow.log_metric(\"val_loss\", history.history['loss'][1])\n",
    "    mlflow.log_metric(\"val_accuracy\", history.history['accuracy'][1]*100)\n",
    "    mlflow.log_metric(\"test_loss\", results[0])\n",
    "    mlflow.log_metric(\"test_accuracy\", results[1]*100)\n",
    "    print(\"Metrics logged to tracking server.\")\n",
    "\n",
    "    tf.keras.models.save_model(model, \"./model\")\n",
    "    print(\"Model saved locally\")\n",
    "\n",
    "    mlflow.log_artifacts(\"./model\")\n",
    "    print(\"Model artifact logged.\")\n",
    "\n",
    "    if mlflow.get_tracking_uri() != 'http://localhost:5000':\n",
    "        try:\n",
    "            tag=[tf.compat.v1.saved_model.tag_constants.SERVING]\n",
    "            key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "            mlflow.tensorflow.log_model(tf_saved_model_dir=\"./model\",\n",
    "                                    tf_meta_graph_tags=tag,\n",
    "                                    tf_signature_def_key=key,\n",
    "                                    artifact_path=\"model\",\n",
    "                                    registered_model_name=\"MobileNetV2\")\n",
    "            print(\"Model sent to registry.\")\n",
    "        except Exception as e:\n",
    "            print(\"Impossible to log model to registry: {}\".format(e))\n",
    "    else:\n",
    "        print(\"No mlflow repository found. Not saving model to it.\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4b90dd24ca00835628f7811727ceb1bfb7054f0d64502a4e9d02e4393d15ff3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
