{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MLFLOW_TRACKING_URI=http://localhost:5000\n",
      "env: MLFLOW_S3_ENDPOINT_URL=http://localhost:9000\n",
      "env: AWS_ACCESS_KEY_ID=minio\n",
      "env: AWS_SECRET_ACCESS_KEY=minio123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 19:03:03.169601: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-19 19:03:03.169649: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Ensure you deployed mlflow\n",
    "%env MLFLOW_TRACKING_URI=http://localhost:5000\n",
    "%env MLFLOW_S3_ENDPOINT_URL=http://localhost:9000\n",
    "%env AWS_ACCESS_KEY_ID=minio\n",
    "%env AWS_SECRET_ACCESS_KEY=minio123\n",
    "\n",
    "# System libraries\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Import DS librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "\n",
    "# Tensorflow Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.python.saved_model import signature_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_for_training(data_path, batch_size):\n",
    "\n",
    "    image_dir = Path(data_path)\n",
    "    # Get filepaths and labels\n",
    "    filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.PNG'))\n",
    "    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "    # Concatenate filepaths and labels\n",
    "    image_df = pd.concat([filepaths, labels], axis=1)\n",
    "\n",
    "    # Separate in train and test data\n",
    "    train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "    # Train data generator\n",
    "    train_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "\n",
    "    # Test data generator\n",
    "    test_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "    )\n",
    "\n",
    "    # Split the data into three categories.\n",
    "    train_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    val_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    test_images = test_generator.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_images, val_images, test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 19:03:05.219383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-09-19 19:03:05.219540: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-19 19:03:05.219585: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-19 19:03:05.219616: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-19 19:03:05.219645: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-19 19:03:05.219673: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-19 19:03:05.219701: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-19 19:03:05.219741: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-19 19:03:05.219774: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-09-19 19:03:05.219781: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-19 19:03:05.220493: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "### Pretrained model\n",
    "\n",
    "# Resize Layer\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Resizing(224,224),\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "])\n",
    "\n",
    "# Load the pretained model\n",
    "pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7515 validated image filenames belonging to 19 classes.\n",
      "Found 1878 validated image filenames belonging to 19 classes.\n",
      "Found 2349 validated image filenames belonging to 19 classes.\n",
      "Training parameters logged to tracking server.\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 19:03:06.557172: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1879/1879 [==============================] - 109s 57ms/step - loss: 2.4770 - accuracy: 0.2874 - val_loss: 1.9493 - val_accuracy: 0.5021\n",
      "Epoch 2/2\n",
      "1879/1879 [==============================] - 98s 52ms/step - loss: 1.6972 - accuracy: 0.5375 - val_loss: 1.3172 - val_accuracy: 0.6869\n",
      "588/588 [==============================] - 26s 44ms/step - loss: 1.2571 - accuracy: 0.7058\n",
      "Metrics logged to tracking server.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 19:07:05.326752: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/workspace/ml_template/.venv/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved locally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/19 19:07:25 INFO mlflow.tensorflow: Validating the specified TensorFlow model by attempting to load it in a new TensorFlow graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impossible to log model artifacts: Connection was closed before we received a valid response from endpoint URL: \"http://localhost:9000/mlflow/1/8a01cfd416a449deb028dc6b29c3340a/artifacts/keras_metadata.pb\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/19 19:07:30 INFO mlflow.tensorflow: Validation succeeded!\n",
      "2022/09/19 19:07:36 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpukndg97j/model, flavor: tensorflow), fall back to return ['tensorflow==2.6.5', 'keras==2.6.0']. Set logging level to DEBUG to see the full traceback.\n",
      "/home/thomas/workspace/ml_template/.venv/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "2022/09/19 19:07:36 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impossible to log model to registry: Connection was closed before we received a valid response from endpoint URL: \"http://localhost:9000/mlflow/1/8a01cfd416a449deb028dc6b29c3340a/artifacts/model/conda.yaml\".\n"
     ]
    }
   ],
   "source": [
    "# Set path to data\n",
    "data_path = \"../data\"\n",
    "\n",
    "# You should ensure you have a local mlflow server running\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"sea_animals_classification\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Exploration\"):\n",
    "\n",
    "    ### hyperparams\n",
    "    denses = [256,256,19]\n",
    "    dropout = [0.2, 0.2]\n",
    "    adam_param = 0.00001\n",
    "    nb_epochs = 2\n",
    "    batch_size = 4\n",
    "    \n",
    "    ### Data Generators\n",
    "    train_images, val_images, test_images = generate_data_for_training(data_path, batch_size)\n",
    "    \n",
    "    ### Model\n",
    "    inputs = pretrained_model.input\n",
    "    x = resize_and_rescale(inputs)\n",
    "    x = Dense(denses[0], activation='relu')(pretrained_model.output)\n",
    "    x = Dropout(dropout[0])(x)\n",
    "    x = Dense(denses[1], activation='relu')(x)\n",
    "    x = Dropout(dropout[1])(x)\n",
    "    outputs = Dense(denses[2], activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    ### Mlflow logging params\n",
    "    mlflow.log_param(\"adam\", adam_param)\n",
    "    mlflow.log_param(\"dropout\", dropout)\n",
    "    mlflow.log_param(\"nb_dense\", denses)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"nb_epochs\", nb_epochs)\n",
    "    print(\"Training parameters logged to tracking server.\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(adam_param),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    start_training_time = time.time()\n",
    "    history = model.fit(\n",
    "        train_images,\n",
    "        steps_per_epoch=len(train_images),\n",
    "        validation_data=val_images,\n",
    "        validation_steps=len(val_images),\n",
    "        epochs=nb_epochs\n",
    "    )\n",
    "    elapsed_training_time = time.time() - start_training_time\n",
    "\n",
    "    ### Evaluate model\n",
    "    results = model.evaluate(test_images, verbose=1)\n",
    "\n",
    "    mlflow.log_metric(\"Training time\", elapsed_training_time)\n",
    "    mlflow.log_metric(\"Training accuracy\", history.history['accuracy'][0]*100)\n",
    "    mlflow.log_metric(\"Validation accuracy\", history.history['accuracy'][1]*100)\n",
    "    mlflow.log_metric(\"Test accuracy\", results[1]*100)\n",
    "    print(\"Metrics logged to tracking server.\")\n",
    "\n",
    "    tf.keras.models.save_model(model, \"./model\")\n",
    "    print(\"Model saved locally\")\n",
    "\n",
    "    try:\n",
    "        mlflow.log_artifacts(\"./model\")\n",
    "        print(\"Model artifact logged.\")\n",
    "    except Exception as e:\n",
    "        print(\"Impossible to log model artifacts: {}\".format(e))\n",
    "\n",
    "    try:\n",
    "        tag=[tf.compat.v1.saved_model.tag_constants.SERVING]\n",
    "        key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "        mlflow.tensorflow.log_model(tf_saved_model_dir=\"./model\",\n",
    "                                tf_meta_graph_tags=tag,\n",
    "                                tf_signature_def_key=key,\n",
    "                                artifact_path=\"model\",\n",
    "                                registered_model_name=\"MobileNetV2\")\n",
    "        print(\"Model sent to registry.\")\n",
    "    except Exception as e:\n",
    "        print(\"Impossible to log model to registry: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impossible to log model artifacts: Connection was closed before we received a valid response from endpoint URL: \"http://localhost:9000/mlflow/1/ca12e7533ab347a6a3bd710e86c87600/artifacts/keras_metadata.pb\".\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mlflow.log_artifacts(\"./model\")\n",
    "    print(\"Model artifact logged.\")\n",
    "except Exception as e:\n",
    "    print(\"Impossible to log model artifacts: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4b90dd24ca00835628f7811727ceb1bfb7054f0d64502a4e9d02e4393d15ff3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
