{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you deployed mlflow\n",
    "%env MLFLOW_TRACKING_URI=http://localhost:5000\n",
    "%env MLFLOW_S3_ENDPOINT_URL=http://localhost:9000\n",
    "%env AWS_ACCESS_KEY_ID=minio\n",
    "%env AWS_SECRET_ACCESS_KEY=minio123\n",
    "\n",
    "# System libraries\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "# Import DS librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "\n",
    "# Tensorflow Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.python.saved_model import signature_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_for_training(data_path, batch_size):\n",
    "\n",
    "    image_dir = Path(data_path)\n",
    "    # Get filepaths and labels\n",
    "    filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.PNG'))\n",
    "    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "    # Concatenate filepaths and labels\n",
    "    image_df = pd.concat([filepaths, labels], axis=1)\n",
    "\n",
    "    # Separate in train and test data\n",
    "    train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "    # Train data generator\n",
    "    train_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "\n",
    "    # Test data generator\n",
    "    test_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input\n",
    "    )\n",
    "\n",
    "    # Split the data into three categories.\n",
    "    train_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    val_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    test_images = test_generator.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_images, val_images, test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pretrained model\n",
    "\n",
    "# Resize Layer\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Resizing(224,224),\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "])\n",
    "\n",
    "# Load the pretained model\n",
    "pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to data\n",
    "data_path = \"../data\"\n",
    "\n",
    "# You should ensure you have a local mlflow server running\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"sea_animals_classification\")\n",
    "with mlflow.start_run(run_name=\"Experiment 1\"):\n",
    "\n",
    "    ### hyperparams\n",
    "    denses = [256,256,19]\n",
    "    dropout = [0.2, 0.2]\n",
    "    adam_param = 0.00001\n",
    "    batch_size = 4\n",
    "    \n",
    "    ### Data Generators\n",
    "    train_images, val_images, test_images = generate_data_for_training(data_path, batch_size)\n",
    "    \n",
    "    ### Model\n",
    "    inputs = pretrained_model.input\n",
    "    x = resize_and_rescale(inputs)\n",
    "    x = Dense(denses[0], activation='relu')(pretrained_model.output)\n",
    "    x = Dropout(dropout[0])(x)\n",
    "    x = Dense(denses[1], activation='relu')(x)\n",
    "    x = Dropout(dropout[1])(x)\n",
    "    outputs = Dense(denses[2], activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    ### Mlflow logging params\n",
    "    mlflow.log_param(\"adam\", adam_param)\n",
    "    mlflow.log_param(\"dropout\", dropout)\n",
    "    mlflow.log_param(\"nb_dense\", denses)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    print(\"Training parameters logged to tracking server.\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(adam_param),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_images,\n",
    "        steps_per_epoch=len(train_images),\n",
    "        validation_data=val_images,\n",
    "        validation_steps=len(val_images),\n",
    "        epochs=2\n",
    "    )\n",
    "\n",
    "    ### Evaluate model\n",
    "    results = model.evaluate(test_images, verbose=1)\n",
    "\n",
    "    mlflow.log_metric(\"train_loss\", history.history['loss'][0])\n",
    "    mlflow.log_metric(\"train_accuracy\", history.history['accuracy'][0]*100)\n",
    "    mlflow.log_metric(\"val_loss\", history.history['loss'][1])\n",
    "    mlflow.log_metric(\"val_accuracy\", history.history['accuracy'][1]*100)\n",
    "    mlflow.log_metric(\"test_loss\", results[0])\n",
    "    mlflow.log_metric(\"test_accuracy\", results[1]*100)\n",
    "    print(\"Metrics logged to tracking server.\")\n",
    "\n",
    "    tf.keras.models.save_model(model, \"./model\")\n",
    "    print(\"Model saved locally\")\n",
    "\n",
    "    mlflow.log_artifacts(\"./model\")\n",
    "    print(\"Model artifact logged.\")\n",
    "\n",
    "    # try:\n",
    "    #     tag=[tf.compat.v1.saved_model.tag_constants.SERVING]\n",
    "    #     key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "    #     mlflow.tensorflow.log_model(tf_saved_model_dir=\"./model\",\n",
    "    #                             tf_meta_graph_tags=tag,\n",
    "    #                             tf_signature_def_key=key,\n",
    "    #                             artifact_path=\"model\",\n",
    "    #                             registered_model_name=\"MobileNetV2\")\n",
    "    #     print(\"Model sent to registry.\")\n",
    "    # except Exception as e:\n",
    "    #     print(\"Impossible to log model to registry: {}\".format(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4b90dd24ca00835628f7811727ceb1bfb7054f0d64502a4e9d02e4393d15ff3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
