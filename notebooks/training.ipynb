{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MLFLOW_TRACKING_URI=http://localhost:5000\n",
      "env: MLFLOW_S3_ENDPOINT_URL=http://localhost:9000\n",
      "env: AWS_ACCESS_KEY_ID=minio\n",
      "env: AWS_SECRET_ACCESS_KEY=minio123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 21:41:32.297717: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-15 21:41:32.297773: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Ensure you deployed mlflow\n",
    "%env MLFLOW_TRACKING_URI=http://localhost:5000\n",
    "%env MLFLOW_S3_ENDPOINT_URL=http://localhost:9000\n",
    "%env AWS_ACCESS_KEY_ID=minio\n",
    "%env AWS_SECRET_ACCESS_KEY=minio123\n",
    "\n",
    "# System libraries\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "# Import DS librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "\n",
    "# Tensorflow Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.python.saved_model import signature_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_for_training(data_path, batch_size):\n",
    "\n",
    "    image_dir = Path(data_path)\n",
    "    # Get filepaths and labels\n",
    "    filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.PNG'))\n",
    "    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "    # Concatenate filepaths and labels\n",
    "    image_df = pd.concat([filepaths, labels], axis=1)\n",
    "\n",
    "    # Separate in train and test data\n",
    "    train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "    # Train data generator\n",
    "    train_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "\n",
    "    # Test data generator\n",
    "    test_generator = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input\n",
    "    )\n",
    "\n",
    "    # Split the data into three categories.\n",
    "    train_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    val_images = train_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    test_images = test_generator.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        x_col='Filepath',\n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_images, val_images, test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 21:41:36.276388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-09-15 21:41:36.276585: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-15 21:41:36.276640: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-15 21:41:36.276682: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-15 21:41:36.276715: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-15 21:41:36.277107: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-15 21:41:36.277179: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-15 21:41:36.277437: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-15 21:41:36.277486: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-09-15 21:41:36.277494: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-15 21:41:36.277787: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "### Pretrained model\n",
    "\n",
    "# Resize Layer\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Resizing(224,224),\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "])\n",
    "\n",
    "# Load the pretained model\n",
    "pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/15 21:41:37 INFO mlflow.tracking.fluent: Experiment with name 'sea_animals_classification' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7515 validated image filenames belonging to 19 classes.\n",
      "Found 1878 validated image filenames belonging to 19 classes.\n",
      "Found 2349 validated image filenames belonging to 19 classes.\n",
      "Training parameters logged to tracking server.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 21:41:38.155784: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "   3/1879 [..............................] - ETA: 1:47 - loss: 3.4204 - accuracy: 0.0833    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 21:41:39.674225: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 19267584 exceeds 10% of free system memory.\n",
      "2022-09-15 21:41:39.680073: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 19613184 exceeds 10% of free system memory.\n",
      "2022-09-15 21:41:39.753236: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 19267584 exceeds 10% of free system memory.\n",
      "2022-09-15 21:41:39.757049: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 19613184 exceeds 10% of free system memory.\n",
      "2022-09-15 21:41:39.811644: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 19267584 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1879/1879 [==============================] - 106s 56ms/step - loss: 2.8431 - accuracy: 0.1649 - val_loss: 2.6300 - val_accuracy: 0.2242\n",
      "Epoch 2/2\n",
      "1879/1879 [==============================] - 106s 57ms/step - loss: 2.5915 - accuracy: 0.2377 - val_loss: 2.4748 - val_accuracy: 0.2487\n",
      "588/588 [==============================] - 26s 44ms/step - loss: 2.4554 - accuracy: 0.2550\n",
      "Metrics logged to tracking server.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 21:45:41.911161: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/workspace/ml_template/.venv/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved locally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/15 21:45:50 INFO mlflow.tensorflow: Validating the specified TensorFlow model by attempting to load it in a new TensorFlow graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifact logged.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/15 21:45:55 INFO mlflow.tensorflow: Validation succeeded!\n"
     ]
    }
   ],
   "source": [
    "# Set path to data\n",
    "data_path = \"../data\"\n",
    "\n",
    "# You should ensure you have a local mlflow server running\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"sea_animals_classification\")\n",
    "with mlflow.start_run(run_name=\"Experiment 1\"):\n",
    "\n",
    "    ### hyperparams\n",
    "    denses = [256,256,19]\n",
    "    dropout = [0.2, 0.2]\n",
    "    adam_param = 0.00001\n",
    "    batch_size = 4\n",
    "    \n",
    "    ### Data Generators\n",
    "    train_images, val_images, test_images = generate_data_for_training(data_path, batch_size)\n",
    "    \n",
    "    ### Model\n",
    "    inputs = pretrained_model.input\n",
    "    x = resize_and_rescale(inputs)\n",
    "    x = Dense(denses[0], activation='relu')(pretrained_model.output)\n",
    "    x = Dropout(dropout[0])(x)\n",
    "    x = Dense(denses[1], activation='relu')(x)\n",
    "    x = Dropout(dropout[1])(x)\n",
    "    outputs = Dense(denses[2], activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    ### Mlflow logging params\n",
    "    mlflow.log_param(\"adam\", adam_param)\n",
    "    mlflow.log_param(\"dropout\", dropout)\n",
    "    mlflow.log_param(\"nb_dense\", denses)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    print(\"Training parameters logged to tracking server.\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(adam_param),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_images,\n",
    "        steps_per_epoch=len(train_images),\n",
    "        validation_data=val_images,\n",
    "        validation_steps=len(val_images),\n",
    "        epochs=2\n",
    "    )\n",
    "\n",
    "    ### Evaluate model\n",
    "    results = model.evaluate(test_images, verbose=1)\n",
    "\n",
    "    mlflow.log_metric(\"train_loss\", history.history['loss'][0])\n",
    "    mlflow.log_metric(\"train_accuracy\", history.history['accuracy'][0]*100)\n",
    "    mlflow.log_metric(\"val_loss\", history.history['loss'][1])\n",
    "    mlflow.log_metric(\"val_accuracy\", history.history['accuracy'][1]*100)\n",
    "    mlflow.log_metric(\"test_loss\", results[0])\n",
    "    mlflow.log_metric(\"test_accuracy\", results[1]*100)\n",
    "    print(\"Metrics logged to tracking server.\")\n",
    "\n",
    "    tf.keras.models.save_model(model, \"./model\")\n",
    "    print(\"Model saved locally\")\n",
    "\n",
    "    mlflow.log_artifacts(\"./model\")\n",
    "    print(\"Model artifact logged.\")\n",
    "\n",
    "    # try:\n",
    "    #     tag=[tf.compat.v1.saved_model.tag_constants.SERVING]\n",
    "    #     key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "    #     mlflow.tensorflow.log_model(tf_saved_model_dir=\"./model\",\n",
    "    #                             tf_meta_graph_tags=tag,\n",
    "    #                             tf_signature_def_key=key,\n",
    "    #                             artifact_path=\"model\",\n",
    "    #                             registered_model_name=\"MobileNetV2\")\n",
    "    #     print(\"Model sent to registry.\")\n",
    "    # except Exception as e:\n",
    "    #     print(\"Impossible to log model to registry: {}\".format(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4b90dd24ca00835628f7811727ceb1bfb7054f0d64502a4e9d02e4393d15ff3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
